@article{aertsLargesampleAssessmentVarying2022,
  title = {Large-Sample Assessment of Varying Spatial Resolution on the Streamflow Estimates of the Wflow\_sbm Hydrological Model},
  author = {Aerts, Jerom P. M. and Hut, Rolf W. and {van de Giesen}, Nick C. and Drost, Niels and {van Verseveld}, Willem J. and Weerts, Albrecht H. and Hazenberg, Pieter},
  year = {2022},
  month = aug,
  journal = {Hydrology and Earth System Sciences},
  volume = {26},
  number = {16},
  pages = {4407--4430},
  publisher = {Copernicus GmbH},
  issn = {1027-5606},
  doi = {10.5194/hess-26-4407-2022},
  url = {https://hess.copernicus.org/articles/26/4407/2022/},
  urldate = {2025-06-24},
  abstract = {Distributed hydrological modelling moves into the realm of hyper-resolution modelling. This results in a plethora of scaling-related challenges that remain unsolved. To the user, in light of model result interpretation, finer-resolution output might imply an increase in understanding of the complex interplay of heterogeneity within the hydrological system. Here we investigate spatial scaling in the form of varying spatial resolution by evaluating the streamflow estimates of the distributed wflow\_sbm hydrological model based on 454 basins from the large-sample CAMELS data set. Model instances are derived at three spatial resolutions, namely 3 km, 1 km, and 200 m. The results show that a finer spatial resolution does not necessarily lead to better streamflow estimates at the basin outlet. Statistical testing of the objective function distributions (Kling--Gupta efficiency (KGE) score) of the three model instances resulted in only a statistical difference between the 3 km and 200 m streamflow estimates. However, an assessment of sampling uncertainty shows high uncertainties surrounding the KGE score throughout the domain. This makes the conclusion based on the statistical testing inconclusive. The results do indicate strong locality in the differences between model instances expressed by differences in KGE scores of on average 0.22 with values larger than 0.5. The results of this study open up research paths that can investigate the changes in flux and state partitioning due to spatial scaling. This will help to further understand the challenges that need to be resolved for hyper-resolution hydrological modelling.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Aerts et al.\Aerts et al._2022_Large-sample assessment of varying spatial resolut.pdf}
}

@article{clarkAbusePopularPerformance2021,
  title = {The {{Abuse}} of {{Popular Performance Metrics}} in {{Hydrologic Modeling}}},
  author = {Clark, Martyn P. and Vogel, Richard M. and Lamontagne, Jonathan R. and Mizukami, Naoki and Knoben, Wouter J. M. and Tang, Guoqiang and Gharari, Shervan and Freer, Jim E. and Whitfield, Paul H. and Shook, Kevin R. and Papalexiou, Simon Michael},
  year = {2021},
  journal = {Water Resources Research},
  volume = {57},
  number = {9},
  pages = {e2020WR029001},
  issn = {1944-7973},
  doi = {10.1029/2020WR029001},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2020WR029001},
  urldate = {2025-06-22},
  abstract = {The goal of this commentary is to critically evaluate the use of popular performance metrics in hydrologic modeling. We focus on the Nash-Sutcliffe Efficiency (NSE) and the Kling-Gupta Efficiency (KGE) metrics, which are both widely used in hydrologic research and practice around the world. Our specific objectives are: (a) to provide tools that quantify the sampling uncertainty in popular performance metrics; (b) to quantify sampling uncertainty in popular performance metrics across a large sample of catchments; and (c) to prescribe the further research that is, needed to improve the estimation, interpretation, and use of popular performance metrics in hydrologic modeling. Our large-sample analysis demonstrates that there is substantial sampling uncertainty in the NSE and KGE estimators. This occurs because the probability distribution of squared errors between model simulations and observations has heavy tails, meaning that performance metrics can be heavily influenced by just a few data points. Our results highlight obvious (yet ignored) abuses of performance metrics that contaminate the conclusions of many hydrologic modeling studies: It is essential to quantify the sampling uncertainty in performance metrics when justifying the use of a model for a specific purpose and when comparing the performance of competing models.},
  copyright = {{\copyright} 2021. The Authors.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Clark et al.\Clark et al._2021_The Abuse of Popular Performance Metrics in Hydrol.pdf}
}

@article{ducSignalprocessingbasedInterpretationNash2023,
  title = {A Signal-Processing-Based Interpretation of the {{Nash}}--{{Sutcliffe}} Efficiency},
  author = {Duc, Le and Sawada, Yohei},
  year = {2023},
  month = may,
  journal = {Hydrology and Earth System Sciences},
  volume = {27},
  number = {9},
  pages = {1827--1839},
  publisher = {Copernicus GmbH},
  issn = {1027-5606},
  doi = {10.5194/hess-27-1827-2023},
  url = {https://hess.copernicus.org/articles/27/1827/2023/},
  urldate = {2025-06-22},
  abstract = {The Nash--Sutcliffe efficiency (NSE) is a widely used score in hydrology, but it is not common in the other environmental sciences. One of the reasons for its unpopularity is that its scientific meaning is somehow unclear in the literature. This study attempts to establish a solid foundation for the NSE from the viewpoint of signal progressing. Thus, a simulation is viewed as a received signal containing a wanted signal (observations) contaminated by an unwanted signal (noise). This view underlines an important role of the error model between simulations and observations.  By assuming an additive error model, it is easy to point out that the NSE is equivalent to an important quantity in signal processing: the signal-to-noise ratio. Moreover, the NSE and the Kling--Gupta efficiency (KGE) are shown to be equivalent, at least when there are no biases, in the sense that they measure the relative magnitude of the power of noise to the power of the variation in observations. The scientific meaning of the NSE suggests a natural way to define NSE=0 as the threshold for good or bad model distinction, and this has no relation to the benchmark simulation that is equal to the observed mean. Corresponding to NSE=0, the threshold of the KGE is given by approximately 0.5.  In the general cases, when the additive error model is replaced by a mixed additive--multiplicative error model, the traditional NSE is shown to be prone to contradiction in model evaluations. Therefore, an extension of the NSE is derived, which only requires one to divide the traditional noise-to-signal ratio by the multiplicative bias. This has a practical implication: if the multiplicative bias is not considered, the traditional NSE and KGE underestimate or overestimate the generalized NSE and KGE when the multiplicative bias is greater or smaller than one, respectively. In particular, the observed mean turns out to be the worst simulation from the viewpoint of the generalized NSE.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Duc and Sawada\Duc and Sawada_2023_A signal-processing-based interpretation of the Na.pdf}
}

@article{guptaDecompositionMeanSquared2009,
  title = {Decomposition of the Mean Squared Error and {{NSE}} Performance Criteria: {{Implications}} for Improving Hydrological Modelling},
  shorttitle = {Decomposition of the Mean Squared Error and {{NSE}} Performance Criteria},
  author = {Gupta, Hoshin V. and Kling, Harald and Yilmaz, Koray K. and Martinez, Guillermo F.},
  year = {2009},
  month = oct,
  journal = {Journal of Hydrology},
  volume = {377},
  number = {1},
  pages = {80--91},
  issn = {0022-1694},
  doi = {10.1016/j.jhydrol.2009.08.003},
  url = {http://www.sciencedirect.com/science/article/pii/S0022169409004843},
  urldate = {2020-09-26},
  abstract = {The mean squared error (MSE) and the related normalization, the Nash--Sutcliffe efficiency (NSE), are the two criteria most widely used for calibration and evaluation of hydrological models with observed data. Here, we present a diagnostically interesting decomposition of NSE (and hence MSE), which facilitates analysis of the relative importance of its different components in the context of hydrological modelling, and show how model calibration problems can arise due to interactions among these components. The analysis is illustrated by calibrating a simple conceptual precipitation-runoff model to daily data for a number of Austrian basins having a broad range of hydro-meteorological characteristics. Evaluation of the results clearly demonstrates the problems that can be associated with any calibration based on the NSE (or MSE) criterion. While we propose and test an alternative criterion that can help to reduce model calibration problems, the primary purpose of this study is not to present an improved measure of model performance. Instead, we seek to show that there are systematic problems inherent with any optimization based on formulations related to the MSE. The analysis and results have implications to the manner in which we calibrate and evaluate environmental models; we discuss these and suggest possible ways forward that may move us towards an improved and diagnostically meaningful approach to model performance evaluation and identification.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Gupta et al\gupta_et_al_2009_decomposition_of_the_mean_squared_error_and_nse_performance_criteria_-.pdf}
}

@techreport{helselStatisticalMethodsWater2002,
  type = {{{USGS Numbered Series}}},
  title = {Statistical Methods in Water Resources},
  author = {Helsel, Dennis R. and Hirsch, Robert M.},
  year = {2002},
  journal = {Statistical methods in water resources},
  series = {Techniques of {{Water-Resources Investigations}}},
  number = {04-A3},
  address = {Reston, VA},
  institution = {U.S. Geological Survey},
  doi = {10.3133/twri04A3},
  url = {http://pubs.er.usgs.gov/publication/twri04A3},
  urldate = {2021-02-14},
  abstract = {PrefaceThis book began as class notes for a course we teach on applied statistical methods to hydrologists of the Water Resources Division, U. S. Geological Survey (USGS). It reflects our attempts to teach statistical methods which are appropriate for analysis of water resources data. As interest in this course has grown outside of the USGS, incentive grew to develop the material into a textbook. The topics covered are those we feel are of greatest usefulness to the practicing water resources scientist. Yet all topics can be directly applied to many other types of environmental data.This book is not a stand-alone text on statistics, or a text on statistical hydrology. For example, in addition to this material we use a textbook on introductory statistics in the USGS training course. As a consequence, discussions of topics such as probability theory required in a general statistics textbook will not be found here. Derivations of most equations are not presented. Important tables included in all general statistics texts, such as quantiles of the normal distribution, are not found here. Neither are details of how statistical distributions should be fitted to flood data -- these are adequately covered in numerous books on statistical hydrology.We have instead chosen to emphasize topics not always found in introductory statistics textbooks, and often not adequately covered in statistical textbooks for scientists and engineers. Tables included here, for example, are those found more often in books on nonparametric statistics than in books likely to have been used in college courses for engineers. This book points the environmental and water resources scientist to robust and nonparametric statistics, and to exploratory data analysis. We believe that the characteristics of environmental (and perhaps most other 'real') data drive analysis methods towards use of robust and nonparametric methods.Exercises are included at the end of chapters. In our course, students compute each type of analysis (t-test, regression, etc.) the first time by hand. We choose the smaller, simpler examples for hand computation. In this way the mechanics of the process are fully understood, and computer software is seen as less mysterious.We wish to acknowledge and thank several other scientists at the U. S. Geological Survey for contributing ideas to this book. In particular, we thank those who have served as the other instructors at the USGS training course. Ed Gilroy has critiqued and improved much of the material found in this book. Tim Cohn has contributed in several areas, particularly to the sections on bias correction in regression, and methods for data below the reporting limit. Richard Alexander has added to the trend analysis chapter, and Charles Crawford has contributed ideas for regression and ANOVA. Their work has undoubtedly made its way into this book},
  keywords = {fundamentals-of-earth-science},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Helsel_Hirsch\Helsel_Hirsch_2002_Statistical methods in water resources.pdf}
}

@techreport{helselStatisticalMethodsWater2020,
  type = {Report},
  title = {Statistical Methods in Water Resources},
  author = {Helsel, Dennis R. and Hirsch, Robert M. and Ryberg, Karen R. and Archfield, Stacey A. and Gilroy, Edward J.},
  year = {2020},
  number = {4-A3},
  pages = {484},
  address = {Reston, VA},
  doi = {10.3133/tm4A3},
  url = {http://pubs.er.usgs.gov/publication/tm4A3},
  langid = {english},
  keywords = {fundamentals-of-earth-science},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Helsel et al\Helsel et al_2020_Statistical methods in water resources.pdf}
}

@techreport{hicksSuspendedSedimentMeasurement2025,
  title = {Suspended {{Sediment}}. {{Measurement}} of {{Fluvial Suspended Sediment Load}} and Its  {{Composition}}},
  author = {Hicks, Murray and Doyle, Martin and Watson, Jeff and Holwerda, Nicholas and Lynch, Barry and Wyatt, Justin and Jones, Haydon and Hill, Reece},
  year = {2025},
  month = may,
  number = {2.0.0},
  pages = {138},
  url = {https://www.nems.org.nz/documents/suspended-sediment},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Hicks et al.\Hicks et al._2025_Measurement of Fluvial Suspended Sediment Load and.pdf}
}

@article{klingRunoffConditionsUpper2012,
  title = {Runoff Conditions in the Upper {{Danube}} Basin under an Ensemble of Climate Change Scenarios},
  author = {Kling, Harald and Fuchs, Martin and Paulin, Maria},
  year = {2012},
  month = mar,
  journal = {Journal of Hydrology},
  volume = {424--425},
  pages = {264--277},
  issn = {0022-1694},
  doi = {10.1016/j.jhydrol.2012.01.011},
  url = {https://www.sciencedirect.com/science/article/pii/S0022169412000431},
  urldate = {2025-06-26},
  abstract = {Runoff conditions are strongly controlled by climate. Therefore, any uncertainties in the projections about future climate directly translate to uncertainties in future runoff. If several climate models are applied with the same emission scenario, there may be large differences in the climate projections due to model related biases and natural climate variability. To address this issue, an ensemble modelling approach -- which considers a set of climate models -- is applied in this study with a monthly, conceptual hydrological model for assessing future runoff conditions in the upper Danube basin (101,810km2). Observed data of the past 120years of the HISTALP data-set are used to evaluate runoff simulations under historic climate variations as well as to test the delta-change method for bias correction of climate data. Uncertainties caused by the hydrological model or by the method for bias correction appear to be small. Projections about future climate are obtained from 21 regional climate models (RCMs) of the ENSEMBLES project for the A1B emission scenario. Evaluation and ranking of the RCMs reveals that some of the models have considerable biases in simulation of spatio-temporal patterns of historic precipitation and temperature. There is however, no systematic relationship between historic performance and projected future change. Even for the better performing RCMs the differences in the simulation results are large. This is a strong argument for using an ensemble modelling approach, which yields a range of future runoff conditions instead of a deterministic projection. In general, a strong decrease of summer runoff is simulated, whereas there is no clear signal for changes in winter runoff. The spread between different RCMs in future seasonal runoff is larger than for the monthly flow duration curve. Overall, the projected changes in future runoff conditions become more pronounced towards the end of the 21st century.},
  file = {C\:\\Users\\TsyplenkovA\\OneDrive - MWLR\\ATS\\Personal\\zotero-library\\Kling et al.\\Kling et al._2012_Runoff conditions in the upper Danube basin under.pdf;C\:\\Users\\TsyplenkovA\\OneDrive - MWLR\\ATS\\Personal\\zotero-library\\Kling et al.\\Kling et al._2012_Runoff conditions in the upper Danube basin under.pdf}
}

@article{knobenTechnicalNoteInherent2019,
  title = {Technical Note: {{Inherent}} Benchmark or Not? {{Comparing Nash}}--{{Sutcliffe}} and {{Kling}}--{{Gupta}} Efficiency Scores},
  shorttitle = {Technical Note},
  author = {Knoben, Wouter J. M. and Freer, Jim E. and Woods, Ross A.},
  year = {2019},
  month = oct,
  journal = {Hydrology and Earth System Sciences},
  volume = {23},
  number = {10},
  pages = {4323--4331},
  publisher = {Copernicus GmbH},
  issn = {1027-5606},
  doi = {10.5194/hess-23-4323-2019},
  url = {https://hess.copernicus.org/articles/23/4323/2019/},
  urldate = {2025-06-22},
  abstract = {A traditional metric used in hydrology to summarize model performance is the Nash--Sutcliffe efficiency (NSE). Increasingly an alternative metric, the Kling--Gupta efficiency (KGE), is used instead. When NSE is used, NSE\&thinsp;=\&thinsp;0 corresponds to using the mean flow as a benchmark predictor. The same reasoning is applied in various studies that use KGE as a metric: negative KGE values are viewed as bad model performance, and only positive values are seen as good model performance. Here we show that using the mean flow as a predictor does not result in KGE\&thinsp;=\&thinsp;0, but instead KGE\&thinsp;=1-{\textsurd}2{$\approx$}-0.41. Thus, KGE values greater than -0.41 indicate that a model improves upon the mean flow benchmark -- even if the model's KGE value is negative. NSE and KGE values cannot be directly compared, because their relationship is non-unique and depends in part on the coefficient of variation of the observed time series. Therefore, modellers who use the KGE metric should not let their understanding of NSE values guide them in interpreting KGE values and instead develop new understanding based on the constitutive parts of the KGE metric and the explicit use of benchmark values to compare KGE scores against. More generally, a strong case can be made for moving away from ad hoc use of aggregated efficiency metrics and towards a framework based on purpose-dependent evaluation metrics and benchmarks that allows for more robust model adequacy assessment.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Knoben et al.\Knoben et al._2019_Technical note Inherent benchmark or not Compari.pdf}
}

@article{kongPhenofitPackageExtracting2022,
  title = {Phenofit: {{An R}} Package for Extracting Vegetation Phenology from Time Series Remote Sensing},
  shorttitle = {Phenofit},
  author = {Kong, Dongdong and McVicar, Tim R. and Xiao, Mingzhong and Zhang, Yongqiang and {Pe{\~n}a-Arancibia}, Jorge L. and Filippa, Gianluca and Xie, Yuxuan and Gu, Xihui},
  year = {2022},
  journal = {Methods in Ecology and Evolution},
  volume = {13},
  number = {7},
  pages = {1508--1527},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13870},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13870},
  urldate = {2023-02-24},
  abstract = {Satellite-derived vegetation indices (VIs) provide a way to analyse vegetation phenology over decades globally. However, these data are often contaminated by different kinds of optical noise (e.g. cloud, cloud shadow, snow, aerosol), making accurate phenology extraction challenging. We present an open-source state-of-the-art R package called phenofit\$\$ phenofit \$\$ to extract vegetation phenological information from satellite-derived VIs. phenofit\$\$ phenofit \$\$ adopts state-of-the-art phenology extraction methods, such as a weight updating function for reducing optical noise contamination, a growing season division function for separating the VI time series into different vegetation cycles, and rough and fine fitting functions for reconstructing VI time series. They work together to make phenology extraction from frequently contaminated VIs easier and more accurate. Compared against other widely used phenology extraction tools, for example, TIMESAT\$\$ {\textbackslash}mathrmTIMESAT \$\$ and phenopix\$\$ phenopix \$\$, phenofit\$\$ phenofit \$\$ provides flexible input and output options, a practical growing season division function, rich curve fitting and phenology extraction functions, and robust performance under different kinds of optical noise. In addition to working with VIs from mesoscale satellites (e.g. MODIS and AVHRR), phenofit\$\$ phenofit \$\$ can also reconstruct vegetation time series and extract phenology using other sources, such as VIs from high-resolution optical satellites (e.g. Sentinel-2 and Landsat) and radar satellites (e.g. Sentinel-1), vegetation greenness indices from digital cameras and gross primary production estimations from eddy-covariance sites. As such, phenofit\$\$ phenofit \$\$ can contribute to the study of ecological process dynamics and assist in effective modelling of global change impacts on vegetation, as caused by climate variability and human intervention. Code and data of case studies are available at https://zenodo.org/record/6425745 (Kong, 2022a).},
  langid = {english},
  keywords = {landuse-change,rstats,savitzky-golay,timeseries,whittaker},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Kong et al\Kong et al_2022_phenofit.pdf}
}

@article{maiTenStrategiesSuccessful2023,
  title = {Ten Strategies towards Successful Calibration of Environmental Models},
  author = {Mai, Juliane},
  year = {2023},
  month = may,
  journal = {Journal of Hydrology},
  volume = {620},
  pages = {129414},
  issn = {0022-1694},
  doi = {10.1016/j.jhydrol.2023.129414},
  url = {https://www.sciencedirect.com/science/article/pii/S0022169423003566},
  urldate = {2025-07-10},
  abstract = {Model calibration is the procedure of finding model settings such that simulated model outputs best match the observed data. Model calibration is necessary when the model parameters cannot directly be measured as is the case with a wide range of environmental models where parameters are conceptually describing upscaled and effective physical processes. Model calibration is therefore an important step of environmental modeling as the model might otherwise provide random outputs if never compared to a ground truth. Model calibration itself is often referred to be an art due to its plenitude of intertwined steps and necessary decisions along the way before a calibration can be carried out or can be regarded successful. This work provides a general guide specifying which steps a modeler needs to undertake, how to diagnose the success of each step, and how to identify the right action to revise steps that were not successful. The procedure is formalized into ten iterative steps generally appearing in calibration experiments. Each step of this ``calibration life cycle'' is either illustrated with an exemplary calibration experiment or providing an explicit checklist the modeler can follow. These ten strategies are: (1) using sensitivity information to guide the calibration, (2) handling of parameters with constraints, (3) handling of data ranging orders of magnitude, (4) choosing the data to base the calibration on, (5) presenting various methods to sample model parameters, (6) finding appropriate parameter ranges, (7) choosing objective functions, (8) selecting a calibration algorithm, (9) determining the success and quality of a multi-objective calibration, and (10) providing a checklist to diagnose calibration performance using ideas introduced in the previous steps. The formal definition of strategies through the calibration process is providing an overview while shedding a light on connections between these main ingredients to calibrate an environmental model and will therefore enable especially novice modelers to succeed.},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Mai\Mai_2023_Ten strategies towards successful calibration of e.pdf}
}

@article{makowskiMethodsAlgorithmsCorrelation2020,
  title = {Methods and {{Algorithms}} for {{Correlation Analysis}} in {{R}}},
  author = {Makowski, Dominique and {Ben-Shachar}, Mattan S. and Patil, Indrajeet and Ludecke, Daniel},
  year = {2020},
  journal = {Journal of Open Source Software},
  volume = {5},
  number = {51},
  pages = {2306},
  doi = {10.21105/joss.02306},
  keywords = {rstats},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Makowski et al.\Makowski et al._2020_Methods and Algorithms for Correlation Analysis in.pdf}
}

@article{markowskaRangrPackageMechanistic2025,
  title = {Rangr: {{An R}} Package for Mechanistic, Spatially Explicit Simulation of Species Range Dynamics},
  shorttitle = {Rangr},
  author = {Markowska, Katarzyna and Malinowska, Katarzyna and Kuczy{\'n}ski, Lechos{\l}aw},
  year = {2025},
  journal = {Methods in Ecology and Evolution},
  volume = {16},
  number = {3},
  pages = {468--476},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.14475},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.14475},
  urldate = {2025-07-10},
  abstract = {Global change driven by human activities is causing profound shifts in species distributions. Understanding the mechanisms that influence these dynamics is crucial for biodiversity management. Several mechanistic, spatially explicit models have been proposed to address this issue, but they do not cover the full range of potential functionalities. We present a new open-source R package called rangr, which integrates population dynamics and dispersal into a mechanistic virtual species simulator. The package can be used to study the effects of environmental change on population growth and range shifts. It extends the capabilities of previously available simulators by allowing simple and straightforward definition of population dynamics (including positive density dependence), extensive possibilities for defining dispersal kernels and the ability to generate virtual ecologist data. We showcased rangr functionality by simulating the invasion of the collared dove (Streptopelia decaocto). First, we demonstrated how to set up a simulation with different dispersal kernels by investigating the role of long-distance dispersal events on colonisation outcome. Second, we showed the use of rangr to assess the potential of an Allee effect to impede biological invasion. Finally, we used the virtual ecologist framework to determine the timeframe required to detect the spread of an invasive species. The rangr package, which comes with extensive documentation and vignettes, is easy to set up, flexible, fast, fully configurable and capable of emulating the observation process. These features make rangr particularly well suited to generating data that replicate existing wildlife monitoring programmes.},
  copyright = {{\copyright} 2025 The Author(s). Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Markowska et al.\Markowska et al._2025_rangr An R package for mechanistic, spatially exp.pdf}
}

@article{melsenRiseNashSutcliffeEfficiency2025,
  title = {The Rise of the {{Nash-Sutcliffe}} Efficiency in Hydrology},
  author = {Melsen, Lieke A. and Puy, Arnald and Torfs, Paul J. J. F. and Saltelli, Andrea},
  year = {2025},
  month = jun,
  journal = {Hydrological Sciences Journal},
  volume = {70},
  number = {8},
  pages = {1248--1259},
  publisher = {Taylor \& Francis},
  issn = {0262-6667},
  doi = {10.1080/02626667.2025.2475105},
  url = {https://doi.org/10.1080/02626667.2025.2475105},
  urldate = {2025-07-12},
  abstract = {The Nash-Sutcliffe efficiency (NSE) is commonly used as a model evaluation metric in hydrology, but its prominence is often taken for granted. This study explores the social factors behind its adoption. Introduced in 1970, the NSE gained traction as computational advancements spurred the growth of hydrological models and evaluation metrics. This, in turn, led to the need to converge on broadly accepted metrics. In 1990, a committee recommended the NSE alongside two other metrics. One of the main developers of SWAT, a widely used hydrological model, adopted only the NSE part of this recommendation, solidifying the NSE's dominance. This storyline shows that the NSE's primacy appears to be derived more from tradition than from any demonstration of technical superiority. To date, path dependence is visible in on-going research efforts resulting from the popularity of the NSE. This historical perspective highlights how social processes have shaped the way hydrological models are evaluated.},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Melsen et al.\Melsen et al._2025_The rise of the Nash-Sutcliffe efficiency in hydro.pdf}
}

@article{mizukamiChoiceCalibrationMetrics2019,
  title = {On the Choice of Calibration Metrics for ``High-Flow'' Estimation Using Hydrologic Models},
  author = {Mizukami, Naoki and Rakovec, Oldrich and Newman, Andrew J. and Clark, Martyn P. and Wood, Andrew W. and Gupta, Hoshin V. and Kumar, Rohini},
  year = {2019},
  month = jun,
  journal = {Hydrology and Earth System Sciences},
  volume = {23},
  number = {6},
  pages = {2601--2614},
  publisher = {Copernicus GmbH},
  issn = {1027-5606},
  doi = {10.5194/hess-23-2601-2019},
  url = {https://hess.copernicus.org/articles/23/2601/2019/},
  urldate = {2025-07-10},
  abstract = {Calibration is an essential step for improving the accuracy of simulations generated using hydrologic models. A key modeling decision is selecting the performance metric to be optimized. It has been common to use squared error performance metrics, or normalized variants such as Nash--Sutcliffe efficiency (NSE), based on the idea that their squared-error nature will emphasize the estimates of high flows. However, we conclude that NSE-based model calibrations actually result in poor reproduction of high-flow events, such as the annual peak flows that are used for flood frequency estimation. Using three different types of performance metrics, we calibrate two hydrological models at a daily step, the Variable Infiltration Capacity (VIC) model and the mesoscale Hydrologic Model (mHM), and evaluate their ability to simulate high-flow events for 492 basins throughout the contiguous United States. The metrics investigated are (1) NSE, (2) Kling--Gupta efficiency (KGE) and its variants, and (3) annual peak flow bias (APFB), where the latter is an application-specific metric that focuses on annual peak flows. As expected, the APFB metric produces the best annual peak flow estimates; however, performance on other high-flow-related metrics is poor. In contrast, the use of NSE results in annual peak flow estimates that are more than 20\&thinsp;\% worse, primarily due to the tendency of NSE to underestimate observed flow variability. On the other hand, the use of KGE results in annual peak flow estimates that are better than from NSE, owing to improved flow time series metrics (mean and variance), with only a slight degradation in performance with respect to other related metrics, particularly when a non-standard weighting of the components of KGE is used. Stochastically generated ensemble simulations based on model residuals show the ability to improve the high-flow metrics, regardless of the deterministic performances. However, we emphasize that improving the fidelity of streamflow dynamics from deterministically calibrated models is still important, as it may improve high-flow metrics (for the right reasons). Overall, this work highlights the need for a deeper understanding of performance metric behavior and design in relation to the desired goals of model calibration.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Mizukami et al.\Mizukami et al._2019_On the choice of calibration metrics for “high-flo.pdf}
}

@article{moriasiHydrologicWaterQuality2015,
  title = {Hydrologic and {{Water Quality Models}}: {{Performance Measures}} and {{Evaluation Criteria}}},
  shorttitle = {Hydrologic and {{Water Quality Models}}},
  author = {Moriasi, Daniel N. and Gitau, Margaret W. and Pai, Naresh and Daggupati, Prasad},
  year = {2015},
  month = dec,
  journal = {Transactions of the ASABE},
  volume = {58},
  number = {6},
  pages = {1763--1785},
  issn = {21510032, 21510040},
  doi = {10.13031/trans.58.10715},
  url = {http://elibrary.asabe.org/abstract.asp?aid=46548&t=3&dabs=Y&redir=&redirType=},
  urldate = {2024-03-06},
  abstract = {Performance measures (PMs) and corresponding performance evaluation criteria (PEC) are important aspects of calibrating and validating hydrologic and water quality models and should be updated with advances in modeling science. We synthesized PMs and PEC from a previous special collection, performed a meta-analysis of performance data reported in recent peer-reviewed literature for three widely published watershed-scale models (SWAT, HSPF, WARMF), and one field-scale model (ADAPT), and provided guidelines for model performance evaluation. Based on the synthesis, meta-analysis, and personal modeling experiences, we recommend the coefficient of determination (R2; in conjunction with the gradient and intercept of the corresponding regression line), Nash-Sutcliffe efficiency (NSE), index of agreement (d), root mean square error (RMSE; alongside the ratio of RMSE and standard deviation of measured data, RSR), percent bias (PBIAS), and several graphical PMs to evaluate model performance. We recommend that model performance can be judged satisfactory for flow simulations if monthly R2 {$>$} 0.70 and d {$>$} 0.75 for field-scale models, and daily, monthly, or annual R2 {$>$} 0.60, NSE {$>$} 0.50, and PBIAS {$\leq$} 15\% for watershed-scale models. Model performance at the watershed scale can be evaluated as satisfactory if monthly R2 {$>$} 0.40 and NSE {$>$} 0.45 and daily, monthly, or annual PBIAS {$\leq$} 20\% for sediment; monthly R2 {$>$} 0.40 and NSE {$>$} 0.35 and daily, monthly, or annual PBIAS {$\leq$} 30\% for phosphorus (P); and monthly R2 {$>$} 0.30 and NSE {$>$} 0.35 and daily, monthly, or annual PBIAS {$\leq$} 30\% for nitrogen (N). For RSR, we recommend that previously published PEC be used as detailed in this article. We also recommend that these PEC be used primarily for the four models for which there were adequate data, and used only with caution for other models. These PEC can be adjusted within acceptable bounds based on additional considerations, such as the quality and quantity of available measured data, spatial and temporal scales, and project scope and magnitude, and updated based on the framework presented herein. This initial meta-analysis sets the stage for a more comprehensive meta-analysis to revise PEC as new PMs and more data become available.},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Moriasi et al\Moriasi et al_2015_Hydrologic and Water Quality Models.pdf}
}

@article{nashRiverFlowForecasting1970,
  title = {River Flow Forecasting through Conceptual Models Part {{I}} --- {{A}} Discussion of Principles},
  author = {Nash, J. E. and Sutcliffe, J. V.},
  year = {1970},
  month = apr,
  journal = {Journal of Hydrology},
  volume = {10},
  number = {3},
  pages = {282--290},
  issn = {0022-1694},
  doi = {10.1016/0022-1694(70)90255-6},
  url = {https://www.sciencedirect.com/science/article/pii/0022169470902556},
  urldate = {2022-10-01},
  abstract = {The principles governing the application of the conceptual model technique to river flow forecasting are discussed. The necessity for a systematic approach to the development and testing of the model is explained and some preliminary ideas suggested.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Nash and Sutcliffe\Nash and Sutcliffe_1970_River flow forecasting through conceptual models p.pdf}
}

@article{oliverTutorialGuideGeostatistics2014,
  title = {A Tutorial Guide to Geostatistics: {{Computing}} and Modelling Variograms and Kriging},
  shorttitle = {A Tutorial Guide to Geostatistics},
  author = {Oliver, M. A. and Webster, R.},
  year = {2014},
  month = feb,
  journal = {CATENA},
  volume = {113},
  pages = {56--69},
  issn = {0341-8162},
  doi = {10.1016/j.catena.2013.09.006},
  url = {https://www.sciencedirect.com/science/article/pii/S0341816213002385},
  urldate = {2025-06-28},
  abstract = {Many environmental scientists are analysing spatial data by geostatistical methods and interpolating from sparse sample data by kriging to make maps. They recognize its merits in providing unbiased estimates with minimum variance. Several statistical packages now have the facilities they require, as do some geographic information systems. In the latter kriging is an option for interpolation that can be done at the press of a few buttons. Unfortunately, the ease conferred by this allows one to krige without understanding and to produce unreliable and even misleading results. Crucial for sound kriging is a plausible function for the spatial covariances or, more widely, of the variogram. The variogram must be estimated reliably and then modelled with valid mathematical functions. This requires an understanding of the assumptions in the underlying theory of random processes on which geostatistics is based. Here we guide readers through computing the sample variogram and modelling it by weighted least-squares fitting. We explain how to choose the most suitable functions by a combination of graphics and statistical diagnostics. Ordinary kriging follows straightforwardly from the model, but small changes in the model function and its parameters can affect the kriging error variances. When kriging is automated these effects remain unknown. We explain the choices to be made when kriging, i.e. whether the support is at points or over blocks, and whether the predictions are global or within moving windows.},
  file = {C\:\\Users\\TsyplenkovA\\OneDrive - MWLR\\ATS\\Personal\\zotero-library\\Oliver and Webster\\Oliver and Webster_2014_A tutorial guide to geostatistics Computing and m.pdf;C\:\\Users\\TsyplenkovA\\OneDrive - MWLR\\ATS\\Personal\\zotero-library\\Oliver and Webster\\Oliver and Webster_2014_A tutorial guide to geostatistics Computing and m.pdf}
}

@incollection{rasmussenGuidelinesProceduresComputing2009,
  title = {Guidelines and Procedures for Computing Time-Series Suspended-Sediment Concentrations and Loads from in-Stream Turbidity-Sensor and Streamflow Data},
  booktitle = {U.{{S}}. {{Geological Survey Techniques}} and {{Methods}} Book 3, Chap. {{C4}}},
  author = {Rasmussen, P. P. and Gray, J. R. and Glysson, G. D. and Ziegler, A. C.},
  year = {2009},
  pages = {53},
  url = {https://pubs.usgs.gov/tm/tm3c4/},
  isbn = {978-1-4113-2410-7},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Rasmussen et al.\Rasmussen et al._2009_Guidelines and procedures for computing time-serie.pdf}
}

@article{sciainiNLMRLandscapetoolsIntegrated2018,
  title = {{{NLMR}} and Landscapetools: {{An}} Integrated Environment for Simulating and Modifying Neutral Landscape Models in {{R}}},
  shorttitle = {{{NLMR}} and Landscapetools},
  author = {Sciaini, Marco and Fritsch, Matthias and Scherer, C{\'e}dric and Simpkins, Craig Eric},
  year = {2018},
  journal = {Methods in Ecology and Evolution},
  volume = {9},
  number = {11},
  pages = {2240--2248},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13076},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13076},
  urldate = {2025-07-10},
  abstract = {Neutral landscape models (NLMs) simulate landscape patterns based on theoretical distributions and can be used to systematically study the effect of landscape structure on ecological processes. NLMs are commonly used in landscape ecology to enhance the findings of field studies as well as in simulation studies to provide an underlying landscape. However, their creation so far has been limited to software that is platform dependent, does not allow a reproducible workflow or is not embedded in R, the prevailing programming language used by ecologists. Here, we present two complementary R packages NLMR and landscapetools, that allow users to generate and manipulate NLMs in a single environment. They grant the simulation of the widest collection of NLMs found in any single piece of software thus far while allowing for easy manipulation in a self-contained and reproducible workflow. The combination of both packages should stimulate a wider usage of NLMs in ecology. NLMR is a comprehensive collection of algorithms with which to simulate NLMs. landscapetools provides a utility toolbox which facilitates an easy workflow with simulated neutral landscapes and other raster data. We show two example applications that illustrate potential use cases for NLMR and landscapetools: First, an agent-based simulation study in which the effect of spatial structure on disease persistence was studied. The second example shows how increases in spatial scaling can introduce biases in calculated landscape metrics. Simplifying the workflow around generating and handling NLMs should encourage an uptake in the usage of NLMs. NLMR and landscapetools are both generic frameworks that can be used in a variety of applications and are a further step to having a unified simulation environment in R for answering spatial research questions.},
  copyright = {{\copyright} 2018 The Authors. Methods in Ecology and Evolution {\copyright} 2018 British Ecological Society},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Sciaini et al.\Sciaini et al._2018_NLMR and landscapetools An integrated environment.pdf}
}

@article{zizkaCoordinateCleanerStandardizedCleaning2019,
  title = {{{CoordinateCleaner}}: {{Standardized}} Cleaning of Occurrence Records from Biological Collection Databases},
  shorttitle = {{{CoordinateCleaner}}},
  author = {Zizka, Alexander and Silvestro, Daniele and Andermann, Tobias and Azevedo, Josu{\'e} and Duarte Ritter, Camila and Edler, Daniel and Farooq, Harith and Herdean, Andrei and Ariza, Mar{\'i}a and Scharn, Ruud and Svantesson, Sten and Wengstr{\"o}m, Niklas and Zizka, Vera and Antonelli, Alexandre},
  year = {2019},
  journal = {Methods in Ecology and Evolution},
  volume = {10},
  number = {5},
  pages = {744--751},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.13152},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13152},
  urldate = {2025-07-10},
  abstract = {Species occurrence records from online databases are an indispensable resource in ecological, biogeographical and palaeontological research. However, issues with data quality, especially incorrect geo-referencing or dating, can diminish their usefulness. Manual cleaning is time-consuming, error prone, difficult to reproduce and limited to known geographical areas and taxonomic groups, making it impractical for datasets with thousands or millions of records. Here, we present CoordinateCleaner, an r-package to scan datasets of species occurrence records for geo-referencing and dating imprecisions and data entry errors in a standardized and reproducible way. CoordinateCleaner is tailored to problems common in biological and palaeontological databases and can handle datasets with millions of records. The software includes (a) functions to flag potentially problematic coordinate records based on geographical gazetteers, (b) a global database of 9,691 geo-referenced biodiversity institutions to identify records that are likely from horticulture or captivity, (c) novel algorithms to identify datasets with rasterized data, conversion errors and strong decimal rounding and (d) spatio-temporal tests for fossils. We describe the individual functions available in CoordinateCleaner and demonstrate them on more than 90 million occurrences of flowering plants from the Global Biodiversity Information Facility (GBIF) and 19,000 fossil occurrences from the Palaeobiology Database (PBDB). We find that in GBIF more than 3.4 million records (3.7\%) are potentially problematic and that 179 of the tested contributing datasets (18.5\%) might be biased by rasterized coordinates. In PBDB, 1205 records (6.3\%) are potentially problematic. All cleaning functions and the biodiversity institution database are open-source and available within the CoordinateCleaner r-package.},
  copyright = {{\copyright} 2019 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
  langid = {english},
  file = {C:\Users\TsyplenkovA\OneDrive - MWLR\ATS\Personal\zotero-library\Zizka et al.\Zizka et al._2019_CoordinateCleaner Standardized cleaning of occurr.pdf}
}
